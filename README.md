# Stage-Aware Event-Based Modeling (SA-EBM) for Disease Progression

This repository contains reproducible codes of the paper of *Stage-Aware Event-Based Modeling (SA-EBM) for Disease Progression*. 

## Tables and Plots

- Table 1 is generated by `notebooks/get-sample-table.ipynb`. 
- Data of Fig. 2, 3, 4, 8, 9, and Table 5 is `all_results.csv`, which is generated by `save_csv.py`. 
- Reproducible codes for Fig. 2, 3, 4, 8, 9 are at [https://observablehq.com/@hongtaoh/mlhc-2025-plots](https://observablehq.com/@hongtaoh/mlhc-2025-plots).
- Table 5 is generated by `notebooks/compare_runtime.ipynb`. 
- Fig. 6, 16-18 are generated by `notebooks/final-adni-plots.ipynb`. 
- Fig. 7 is generate by `notebooks/plot_bm_distributions.ipynb`. 
- Fig. 10?

## Procedure on CHTC

If you have access to CHTC, the procedure is:

To update the `pysaebm` package, run `bash updatepkg.sh`.

First, generate data by running `bash gen.sh`. Please modify `gen.py` and `gen.sh` as needed. 

Then, run `gen_combo.py` to generate `all_combinations.txt`. 

Next, run `bash run.sh`. Modify `run.sh` as needed. Results will be stored in `algo_results`. Logs are in `logs`.

To get `all_results.csv`, run `python3 savd_csv.py`. 

If to get ADNI results, run `bash run2.sh`. Results will be found in `adni_results`. 

Note that the results on ADNI (log tranformming TAU and PTAU) are in `adni_results_log_transformations`. 

## Locally

If you want to replicate our study by running locally, first, make sure you have the latest version of `pysaebm` by `pip install pysaebm`. 

Next, generate data by running `bash gen.sh`. You need to modify `gen.sh` to keep the data folder, instead of compress it and delete it. 

Next, you can use `run_local.py` this way:

```py
python3 run_local.py "j200_r0.25_Esn_kjContinuousBeta_m0"
```

This only runs for one dataset, though. 

## Doc strings for folders and files 

- `adni_results`: results of ADNI. 
- `adni_results_log_transformations`: results of ADNI with log transformations on TAU and PTAU. 
- `algo_results`: results of the 9k datasets on different algorithms. 
- `experimental_notebooks`: notebooks for exploratory purposes. 
- `local_results`: if you run `run_local.py`, you'll get the results here. 
- `logs`: logs when you run the 9k datasets on chtc. 
- `notebooks`: final notebooks used for the paper. 
- `toy_data`: toy data to test. 
- `all_results.csv`: the final results of the 9k datasets. 
- `config.yaml`: configurations. 
- `gen_combo.py`: generate `all_combinations.txt`. 
- `gen.py`, `gen.sh`: to generate data for the experiments. 
- `run_adni.py`, `run_adni.sh`, `run_adni.sub`: files needed to run `run2.sh`. 
- `run.py`: utility functions. 
- `run_mlhc.py`, `run_mlhc.sh`, and `run_mlhc.sub`: files to run `run.sh`. 
- `save_csv.py`: to generate `all_results.csv`. 
- `true_order_and_stages.json`: the results if you run `gen.sh`. 
- `utils_adni.py`: utility functions. 






