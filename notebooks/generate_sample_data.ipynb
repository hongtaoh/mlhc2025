{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to generate sample data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysaebm import generate, get_params_path\n",
    "import os\n",
    "import numpy as np \n",
    "import json \n",
    "import yaml\n",
    "\n",
    "def load_config():\n",
    "    # Use the current working directory (typically where Jupyter Book builds from)\n",
    "    config_path = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"config.yaml\"))\n",
    "    \n",
    "    with open(config_path, \"r\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "def convert_np_types(obj):\n",
    "    \"\"\"Convert numpy types in a nested dictionary to Python standard types.\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_np_types(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_np_types(item) for item in obj]\n",
    "    elif isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return convert_np_types(obj.tolist())\n",
    "    else:\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config:\n",
      "{\n",
      "    \"N_VARIANTS\": 50,\n",
      "    \"NStartpoints\": 10,\n",
      "    \"Niterations\": 1000,\n",
      "    \"N_MCMC\": 10000,\n",
      "    \"N_SHUFFLE\": 2,\n",
      "    \"BURN_IN\": 500,\n",
      "    \"THINNING\": 1,\n",
      "    \"GEN_SEED\": 42,\n",
      "    \"JS\": [\n",
      "        50,\n",
      "        200,\n",
      "        500,\n",
      "        1000\n",
      "    ],\n",
      "    \"MCMC_SEED\": 53,\n",
      "    \"RS\": [\n",
      "        0.1,\n",
      "        0.25,\n",
      "        0.5,\n",
      "        0.75,\n",
      "        0.9\n",
      "    ],\n",
      "    \"N_BOOTSTRAP\": 50,\n",
      "    \"SA_EBM_ALGO_NAMES\": [\n",
      "        \"conjugate_priors\",\n",
      "        \"mle\",\n",
      "        \"kde\",\n",
      "        \"em\",\n",
      "        \"hard_kmeans\"\n",
      "    ],\n",
      "    \"OTHER_ALGO_NAMES\": [\n",
      "        \"debm\",\n",
      "        \"debm_gmm\",\n",
      "        \"ucl_gmm\",\n",
      "        \"ucl_kde\"\n",
      "    ],\n",
      "    \"OUTPUT_DIR\": \"algo_results\",\n",
      "    \"EXPERIMENT_NAMES\": [\n",
      "        \"sn_kjOrdinalDM_xnjNormal\",\n",
      "        \"sn_kjOrdinalDM_xnjNonNormal\",\n",
      "        \"sn_kjOrdinalUniform_xnjNormal\",\n",
      "        \"sn_kjOrdinalUniform_xnjNonNormal\",\n",
      "        \"sn_kjContinuousUniform\",\n",
      "        \"sn_kjContinuousBeta\",\n",
      "        \"xiNearNormal_kjContinuousUniform\",\n",
      "        \"xiNearNormal_kjContinuousBeta\",\n",
      "        \"xiNearNormalWithNoise_kjContinuousBeta\"\n",
      "    ]\n",
      "}\n",
      "Data generation complete. Files saved in ../toy_data/\n",
      "Data generation complete. Files saved in ../toy_data/\n",
      "Data generation complete. Files saved in ../toy_data/\n",
      "Data generation complete. Files saved in ../toy_data/\n",
      "Data generation complete. Files saved in ../toy_data/\n",
      "Data generation complete. Files saved in ../toy_data/\n",
      "Data generation complete. Files saved in ../toy_data/\n",
      "Data generation complete. Files saved in ../toy_data/\n",
      "Data generation complete. Files saved in ../toy_data/\n"
     ]
    }
   ],
   "source": [
    "# Get path to default parameters\n",
    "params_file = get_params_path()\n",
    "\n",
    "config = load_config()\n",
    "print(\"Loaded config:\")\n",
    "print(json.dumps(config, indent=4))\n",
    "\n",
    "OUTPUT_DIR = '../toy_data'\n",
    "\n",
    "all_dicts = []\n",
    "\n",
    "for exp_name in config['EXPERIMENT_NAMES']:\n",
    "    true_order_and_stages_dicts = generate(\n",
    "            experiment_name = exp_name,\n",
    "            params_file=params_file,\n",
    "            js = [200],\n",
    "            rs = [0.25],\n",
    "            num_of_datasets_per_combination=1,\n",
    "            output_dir=OUTPUT_DIR,\n",
    "            seed=config['GEN_SEED'],\n",
    "            keep_all_cols = True,\n",
    "        )\n",
    "    all_dicts.append(true_order_and_stages_dicts)\n",
    "\n",
    "combined = {k: v for d in all_dicts for k, v in d.items()}\n",
    "combined = convert_np_types(combined)\n",
    "\n",
    "# Dump the JSON\n",
    "with open(f\"{OUTPUT_DIR}/true_order_and_stages.json\", \"w\") as f:\n",
    "    json.dump(combined, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlhc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
